{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178,
     "referenced_widgets": [
      "7c676819d0bc46deab79af55576cb680",
      "6b0b2a196cf04039aae27141cbb342b8",
      "8841468b83e14fc793f090f195562ecc",
      "e85aa133d0024c7d918d19d49ebfda1f",
      "f2aab9cbec914614958c8429ff658730",
      "0f42b149c38040799aa77a06e1be37a3",
      "88e2fe42ee704457951b0a433aa7e6c3",
      "d8bdade393b64daeaa3211d74b7962ff",
      "f23de0e1ffc8491fae098ba5f55c2e00",
      "aca0418d6fe24fa3a9a9c939ad83c012",
      "7d8dff2afdfe41968ee79c9acdbdcb42"
     ]
    },
    "executionInfo": {
     "elapsed": 15166,
     "status": "ok",
     "timestamp": 1709912219824,
     "user": {
      "displayName": "송우석",
      "userId": "17544301414917834266"
     },
     "user_tz": -540
    },
    "id": "YrLNgZU9f1tt",
    "outputId": "d84850ec-9313-40fc-d257-29708e675fdf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wooseok/anaconda3/envs/peft/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.76s/it]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import torch, pandas, torch.nn, tempfile,os,pickle\n",
    "from collections import namedtuple\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "from accelerate import Accelerator\n",
    "from torch import nn\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, PrefixTuningConfig, PromptTuningInit, PromptTuningConfig, TaskType, PeftType\n",
    "from transformers import BitsAndBytesConfig,LlamaTokenizer,LlamaForCausalLM,GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "\n",
    "from peft import prepare_model_for_kbit_training\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "device = 'cuda'\n",
    "model_path =\"meta-llama/Llama-2-7b-chat-hf\"\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type=\"nf4\",\n",
    "   bnb_4bit_use_double_quant=True,\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "model =LlamaForCausalLM.from_pretrained(model_path,\n",
    "                                    #load_in_8bit=True, #  7.7GB로\n",
    "                                        quantization_config =nf4_config, #  4.4GB로 \n",
    "                                        device_map=\"auto\", # gpu 꽉차면 cpu로 올려줌 \n",
    "                                        \n",
    "                                       )\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>reference</th>\n",
       "      <th>act</th>\n",
       "      <th>act_label</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Hey man , you wanna buy some weed ? ]</td>\n",
       "      <td>Some what ?</td>\n",
       "      <td>2</td>\n",
       "      <td>Question</td>\n",
       "      <td>[1, 894, 2, 1, 18637, 767, 1919, 366, 281, 971...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Hey man , you wanna buy some weed ? ,  Some w...</td>\n",
       "      <td>Oh , umm , no thanks .</td>\n",
       "      <td>4</td>\n",
       "      <td>Commissive</td>\n",
       "      <td>[1, 1876, 790, 573, 2, 1, 18637, 767, 1919, 36...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[The taxi drivers are on strike again . ]</td>\n",
       "      <td>What for ?</td>\n",
       "      <td>2</td>\n",
       "      <td>Question</td>\n",
       "      <td>[1, 894, 2, 1, 450, 8818, 29875, 18563, 526, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[The taxi drivers are on strike again . ,  Wha...</td>\n",
       "      <td>It is really a hot potato .</td>\n",
       "      <td>1</td>\n",
       "      <td>Inform</td>\n",
       "      <td>[1, 15162, 2, 1, 450, 8818, 29875, 18563, 526,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[We've managed to reduce our energy consumptio...</td>\n",
       "      <td>That's excellent . How have you managed that ?</td>\n",
       "      <td>2</td>\n",
       "      <td>Question</td>\n",
       "      <td>[1, 894, 2, 1, 1334, 29915, 345, 8745, 304, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[We've managed to reduce our energy consumptio...</td>\n",
       "      <td>What does that mean exactly ?</td>\n",
       "      <td>2</td>\n",
       "      <td>Question</td>\n",
       "      <td>[1, 894, 2, 1, 1334, 29915, 345, 8745, 304, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Believe it or not , tea is the most popular b...</td>\n",
       "      <td>Well , people from Asia to Europe all enjoy t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Inform</td>\n",
       "      <td>[1, 15162, 2, 1, 3741, 2418, 372, 470, 451, 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Believe it or not , tea is the most popular b...</td>\n",
       "      <td>Yes , Chinese people love drinking tea so muc...</td>\n",
       "      <td>1</td>\n",
       "      <td>Inform</td>\n",
       "      <td>[1, 15162, 2, 1, 3741, 2418, 372, 470, 451, 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[What are your personal weaknesses ? ]</td>\n",
       "      <td>I ’ m afraid I ’ m a poor talker . I ’ m not ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Inform</td>\n",
       "      <td>[1, 15162, 2, 1, 1724, 526, 596, 7333, 8062, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[What are your personal weaknesses ? ,  I ’ m ...</td>\n",
       "      <td>I don ’ t try to lead people . I ’ d rather c...</td>\n",
       "      <td>1</td>\n",
       "      <td>Inform</td>\n",
       "      <td>[1, 15162, 2, 1, 1724, 526, 596, 7333, 8062, 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0             [Hey man , you wanna buy some weed ? ]   \n",
       "1  [Hey man , you wanna buy some weed ? ,  Some w...   \n",
       "2          [The taxi drivers are on strike again . ]   \n",
       "3  [The taxi drivers are on strike again . ,  Wha...   \n",
       "4  [We've managed to reduce our energy consumptio...   \n",
       "5  [We've managed to reduce our energy consumptio...   \n",
       "6  [Believe it or not , tea is the most popular b...   \n",
       "7  [Believe it or not , tea is the most popular b...   \n",
       "8             [What are your personal weaknesses ? ]   \n",
       "9  [What are your personal weaknesses ? ,  I ’ m ...   \n",
       "\n",
       "                                           reference  act   act_label  \\\n",
       "0                                       Some what ?     2    Question   \n",
       "1                            Oh , umm , no thanks .     4  Commissive   \n",
       "2                                        What for ?     2    Question   \n",
       "3                       It is really a hot potato .     1      Inform   \n",
       "4    That's excellent . How have you managed that ?     2    Question   \n",
       "5                     What does that mean exactly ?     2    Question   \n",
       "6   Well , people from Asia to Europe all enjoy t...    1      Inform   \n",
       "7   Yes , Chinese people love drinking tea so muc...    1      Inform   \n",
       "8   I ’ m afraid I ’ m a poor talker . I ’ m not ...    1      Inform   \n",
       "9   I don ’ t try to lead people . I ’ d rather c...    1      Inform   \n",
       "\n",
       "                                        input_tokens  \n",
       "0  [1, 894, 2, 1, 18637, 767, 1919, 366, 281, 971...  \n",
       "1  [1, 1876, 790, 573, 2, 1, 18637, 767, 1919, 36...  \n",
       "2  [1, 894, 2, 1, 450, 8818, 29875, 18563, 526, 3...  \n",
       "3  [1, 15162, 2, 1, 450, 8818, 29875, 18563, 526,...  \n",
       "4  [1, 894, 2, 1, 1334, 29915, 345, 8745, 304, 10...  \n",
       "5  [1, 894, 2, 1, 1334, 29915, 345, 8745, 304, 10...  \n",
       "6  [1, 15162, 2, 1, 3741, 2418, 372, 470, 451, 19...  \n",
       "7  [1, 15162, 2, 1, 3741, 2418, 372, 470, 451, 19...  \n",
       "8  [1, 15162, 2, 1, 1724, 526, 596, 7333, 8062, 2...  \n",
       "9  [1, 15162, 2, 1, 1724, 526, 596, 7333, 8062, 2...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/home/wooseok/peft/FT_input_datasets_llama.pickle', 'rb') as fr:\n",
    "    data = pickle.load(fr)\n",
    "del_index = []\n",
    "for i in range(len(data)):\n",
    "    if len(data['context'][i]) %2 ==0:\n",
    "        del_index.append(i)\n",
    "data.drop(del_index, axis=0, inplace=True)\n",
    "data=data.reset_index(drop = True)\n",
    "data = data[:10]\n",
    "data     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'prompt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/peft/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'prompt'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m gen \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data))):\n\u001b[0;32m---> 36\u001b[0m     gen\u001b[38;5;241m.\u001b[39mappend(generate_sentence(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[j],j))\n\u001b[1;32m     37\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgen\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m gen\n\u001b[1;32m     38\u001b[0m data\n",
      "File \u001b[0;32m~/anaconda3/envs/peft/lib/python3.9/site-packages/pandas/core/frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/peft/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'prompt'"
     ]
    }
   ],
   "source": [
    "def generate_sentence(prompt,j):\n",
    "\n",
    "    print(prompt)    \n",
    "    print(\" *******************    \")\n",
    "    \n",
    "    input_id = tokenizer.encode(prompt,return_tensors ='pt')\n",
    "    output_so_far  = input_id\n",
    "    last = output_so_far[:, -1:] # 마지막 단어\n",
    "    past = model(output_so_far[:, :-1],return_dict =True)[\"past_key_values\"] #이전단어들의 key_value\n",
    "    \n",
    "    \n",
    "    for i in range(10):\n",
    "        lm_output= model(last, past_key_values=past,use_cache = True,\n",
    "                         return_dict=True,output_hidden_states=True)  \n",
    "        logit, past = (\n",
    "            lm_output[\"logits\"], \n",
    "            # torch.Size([1, 1, 32000]\n",
    "            \n",
    "            lm_output[\"past_key_values\"]) \n",
    "            # 32, 2, torch.Size([1, 32, Sequence_len, 128]) )\n",
    "        probs = nn.functional.softmax(logit[:,-1,:], dim=-1)\n",
    "        last = torch.topk(probs, k=1, dim=-1)[1]\n",
    "        \n",
    "        output_so_far = torch.cat((output_so_far,last),dim=1)\n",
    "        \n",
    "        del lm_output\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        if last[0] ==torch.tensor(tokenizer.eos_token_id):\n",
    "            break\n",
    "    print(tokenizer.decode(output_so_far[0][len(input_id[0]):])) \n",
    "    return tokenizer.decode(output_so_far[0][len(input_id[0]):])\n",
    "\n",
    "gen = []\n",
    "for j in tqdm(range(len(data))):\n",
    "    gen.append(generate_sentence(data['prompt'][j],j))\n",
    "data['gen'] = gen\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOBGc3WgJTvwgp7jiBxY7Pp",
   "machine_shape": "hm",
   "mount_file_id": "1PV25_eTqPr-jNz23RBXDrs1KICBozvHF",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0f42b149c38040799aa77a06e1be37a3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b0b2a196cf04039aae27141cbb342b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f42b149c38040799aa77a06e1be37a3",
      "placeholder": "​",
      "style": "IPY_MODEL_88e2fe42ee704457951b0a433aa7e6c3",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "7c676819d0bc46deab79af55576cb680": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6b0b2a196cf04039aae27141cbb342b8",
       "IPY_MODEL_8841468b83e14fc793f090f195562ecc",
       "IPY_MODEL_e85aa133d0024c7d918d19d49ebfda1f"
      ],
      "layout": "IPY_MODEL_f2aab9cbec914614958c8429ff658730"
     }
    },
    "7d8dff2afdfe41968ee79c9acdbdcb42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8841468b83e14fc793f090f195562ecc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8bdade393b64daeaa3211d74b7962ff",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f23de0e1ffc8491fae098ba5f55c2e00",
      "value": 2
     }
    },
    "88e2fe42ee704457951b0a433aa7e6c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aca0418d6fe24fa3a9a9c939ad83c012": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8bdade393b64daeaa3211d74b7962ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e85aa133d0024c7d918d19d49ebfda1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aca0418d6fe24fa3a9a9c939ad83c012",
      "placeholder": "​",
      "style": "IPY_MODEL_7d8dff2afdfe41968ee79c9acdbdcb42",
      "value": " 2/2 [00:05&lt;00:00,  2.43s/it]"
     }
    },
    "f23de0e1ffc8491fae098ba5f55c2e00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f2aab9cbec914614958c8429ff658730": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
