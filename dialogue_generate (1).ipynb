{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178,
     "referenced_widgets": [
      "7c676819d0bc46deab79af55576cb680",
      "6b0b2a196cf04039aae27141cbb342b8",
      "8841468b83e14fc793f090f195562ecc",
      "e85aa133d0024c7d918d19d49ebfda1f",
      "f2aab9cbec914614958c8429ff658730",
      "0f42b149c38040799aa77a06e1be37a3",
      "88e2fe42ee704457951b0a433aa7e6c3",
      "d8bdade393b64daeaa3211d74b7962ff",
      "f23de0e1ffc8491fae098ba5f55c2e00",
      "aca0418d6fe24fa3a9a9c939ad83c012",
      "7d8dff2afdfe41968ee79c9acdbdcb42"
     ]
    },
    "executionInfo": {
     "elapsed": 15166,
     "status": "ok",
     "timestamp": 1709912219824,
     "user": {
      "displayName": "송우석",
      "userId": "17544301414917834266"
     },
     "user_tz": -540
    },
    "id": "YrLNgZU9f1tt",
    "outputId": "d84850ec-9313-40fc-d257-29708e675fdf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wooseok/anaconda3/envs/peft/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.76s/it]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import torch, pandas, torch.nn, tempfile,os,pickle\n",
    "from collections import namedtuple\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "from accelerate import Accelerator\n",
    "from torch import nn\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, PrefixTuningConfig, PromptTuningInit, PromptTuningConfig, TaskType, PeftType\n",
    "from transformers import BitsAndBytesConfig,LlamaTokenizer,LlamaForCausalLM,GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "\n",
    "from peft import prepare_model_for_kbit_training\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "device = 'cuda'\n",
    "model_path =\"meta-llama/Llama-2-7b-chat-hf\"\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type=\"nf4\",\n",
    "   bnb_4bit_use_double_quant=True,\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "model =LlamaForCausalLM.from_pretrained(model_path,\n",
    "                                    #load_in_8bit=True, #  7.7GB로\n",
    "                                        quantization_config =nf4_config, #  4.4GB로 \n",
    "                                        device_map=\"auto\", # gpu 꽉차면 cpu로 올려줌 \n",
    "                                        \n",
    "                                       )\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>reference</th>\n",
       "      <th>act</th>\n",
       "      <th>act_label</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Hey man , you wanna buy some weed ? ]</td>\n",
       "      <td>Some what ?</td>\n",
       "      <td>2</td>\n",
       "      <td>Question</td>\n",
       "      <td>[1, 894, 2, 1, 18637, 767, 1919, 366, 281, 971...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Hey man , you wanna buy some weed ? ,  Some w...</td>\n",
       "      <td>Oh , umm , no thanks .</td>\n",
       "      <td>4</td>\n",
       "      <td>Commissive</td>\n",
       "      <td>[1, 1876, 790, 573, 2, 1, 18637, 767, 1919, 36...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[The taxi drivers are on strike again . ]</td>\n",
       "      <td>What for ?</td>\n",
       "      <td>2</td>\n",
       "      <td>Question</td>\n",
       "      <td>[1, 894, 2, 1, 450, 8818, 29875, 18563, 526, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[The taxi drivers are on strike again . ,  Wha...</td>\n",
       "      <td>It is really a hot potato .</td>\n",
       "      <td>1</td>\n",
       "      <td>Inform</td>\n",
       "      <td>[1, 15162, 2, 1, 450, 8818, 29875, 18563, 526,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[We've managed to reduce our energy consumptio...</td>\n",
       "      <td>That's excellent . How have you managed that ?</td>\n",
       "      <td>2</td>\n",
       "      <td>Question</td>\n",
       "      <td>[1, 894, 2, 1, 1334, 29915, 345, 8745, 304, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[We've managed to reduce our energy consumptio...</td>\n",
       "      <td>What does that mean exactly ?</td>\n",
       "      <td>2</td>\n",
       "      <td>Question</td>\n",
       "      <td>[1, 894, 2, 1, 1334, 29915, 345, 8745, 304, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Believe it or not , tea is the most popular b...</td>\n",
       "      <td>Well , people from Asia to Europe all enjoy t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Inform</td>\n",
       "      <td>[1, 15162, 2, 1, 3741, 2418, 372, 470, 451, 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Believe it or not , tea is the most popular b...</td>\n",
       "      <td>Yes , Chinese people love drinking tea so muc...</td>\n",
       "      <td>1</td>\n",
       "      <td>Inform</td>\n",
       "      <td>[1, 15162, 2, 1, 3741, 2418, 372, 470, 451, 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[What are your personal weaknesses ? ]</td>\n",
       "      <td>I ’ m afraid I ’ m a poor talker . I ’ m not ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Inform</td>\n",
       "      <td>[1, 15162, 2, 1, 1724, 526, 596, 7333, 8062, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[What are your personal weaknesses ? ,  I ’ m ...</td>\n",
       "      <td>I don ’ t try to lead people . I ’ d rather c...</td>\n",
       "      <td>1</td>\n",
       "      <td>Inform</td>\n",
       "      <td>[1, 15162, 2, 1, 1724, 526, 596, 7333, 8062, 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0             [Hey man , you wanna buy some weed ? ]   \n",
       "1  [Hey man , you wanna buy some weed ? ,  Some w...   \n",
       "2          [The taxi drivers are on strike again . ]   \n",
       "3  [The taxi drivers are on strike again . ,  Wha...   \n",
       "4  [We've managed to reduce our energy consumptio...   \n",
       "5  [We've managed to reduce our energy consumptio...   \n",
       "6  [Believe it or not , tea is the most popular b...   \n",
       "7  [Believe it or not , tea is the most popular b...   \n",
       "8             [What are your personal weaknesses ? ]   \n",
       "9  [What are your personal weaknesses ? ,  I ’ m ...   \n",
       "\n",
       "                                           reference  act   act_label  \\\n",
       "0                                       Some what ?     2    Question   \n",
       "1                            Oh , umm , no thanks .     4  Commissive   \n",
       "2                                        What for ?     2    Question   \n",
       "3                       It is really a hot potato .     1      Inform   \n",
       "4    That's excellent . How have you managed that ?     2    Question   \n",
       "5                     What does that mean exactly ?     2    Question   \n",
       "6   Well , people from Asia to Europe all enjoy t...    1      Inform   \n",
       "7   Yes , Chinese people love drinking tea so muc...    1      Inform   \n",
       "8   I ’ m afraid I ’ m a poor talker . I ’ m not ...    1      Inform   \n",
       "9   I don ’ t try to lead people . I ’ d rather c...    1      Inform   \n",
       "\n",
       "                                        input_tokens  \n",
       "0  [1, 894, 2, 1, 18637, 767, 1919, 366, 281, 971...  \n",
       "1  [1, 1876, 790, 573, 2, 1, 18637, 767, 1919, 36...  \n",
       "2  [1, 894, 2, 1, 450, 8818, 29875, 18563, 526, 3...  \n",
       "3  [1, 15162, 2, 1, 450, 8818, 29875, 18563, 526,...  \n",
       "4  [1, 894, 2, 1, 1334, 29915, 345, 8745, 304, 10...  \n",
       "5  [1, 894, 2, 1, 1334, 29915, 345, 8745, 304, 10...  \n",
       "6  [1, 15162, 2, 1, 3741, 2418, 372, 470, 451, 19...  \n",
       "7  [1, 15162, 2, 1, 3741, 2418, 372, 470, 451, 19...  \n",
       "8  [1, 15162, 2, 1, 1724, 526, 596, 7333, 8062, 2...  \n",
       "9  [1, 15162, 2, 1, 1724, 526, 596, 7333, 8062, 2...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/home/wooseok/peft/FT_input_datasets_llama.pickle', 'rb') as fr:\n",
    "    data = pickle.load(fr)\n",
    "del_index = []\n",
    "for i in range(len(data)):\n",
    "    if len(data['context'][i]) %2 ==0:\n",
    "        del_index.append(i)\n",
    "data.drop(del_index, axis=0, inplace=True)\n",
    "data=data.reset_index(drop = True)\n",
    "data = data[:10]\n",
    "data     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12993.51it/s]\n"
     ]
    }
   ],
   "source": [
    "def make_prompt(j):\n",
    "    sys_prompt = '[INST] <<SYS>>\\nAssume you are user and continue the conversation.\\n<</SYS>>\\n'\n",
    "    utter1 = data['context'][j][0] + '[/INST]\\n'\n",
    "    prompt = sys_prompt + utter1\n",
    "    #prompt = utter1\n",
    "    for i in range(len(data['context'][j])-1):\n",
    "        \n",
    "        if (i+1)%2 ==1 :\n",
    "            #print(\"??\")\n",
    "            utter2 = data['context'][j][i+1] + '</s>'\n",
    "        else: \n",
    "            #print(\"!@!\")\n",
    "            utter2 = '\\n<s>[INST]'+data['context'][j][i+1] + '[/INST]'\n",
    "        prompt = prompt + utter2\n",
    "    return prompt\n",
    "prompt_gen = []\n",
    "for j in tqdm(range(len(data))):\n",
    "    prompt_gen.append(make_prompt(j))\n",
    "data['prompt']=prompt_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] <<SYS>>\n",
      "Assume you are user and continue the conversation.\n",
      "<</SYS>>\n",
      "Hey man , you wanna buy some weed ? [/INST]\n",
      "\n",
      " *******************    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▍                                                                           | 1/10 [00:03<00:34,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I cannot assist you with purchasing illegal substances\n",
      "[INST] <<SYS>>\n",
      "Assume you are user and continue the conversation.\n",
      "<</SYS>>\n",
      "Hey man , you wanna buy some weed ? [/INST]\n",
      " Some what ? </s>\n",
      "<s>[INST] Weed ! You know ? Pot , Ganja , Mary Jane some chronic ! [/INST]\n",
      " *******************    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▊                                                                   | 2/10 [00:07<00:30,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I see. Well, I don't\n",
      "[INST] <<SYS>>\n",
      "Assume you are user and continue the conversation.\n",
      "<</SYS>>\n",
      "The taxi drivers are on strike again . [/INST]\n",
      "\n",
      " *******************    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████████████▏                                                          | 3/10 [00:11<00:25,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh no, that's really frustrating\n",
      "[INST] <<SYS>>\n",
      "Assume you are user and continue the conversation.\n",
      "<</SYS>>\n",
      "The taxi drivers are on strike again . [/INST]\n",
      " What for ? </s>\n",
      "<s>[INST] They want the government to reduce the price of the gasoline . [/INST]\n",
      " *******************    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▌                                                  | 4/10 [00:14<00:22,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Oh, I see. That's quite\n",
      "[INST] <<SYS>>\n",
      "Assume you are user and continue the conversation.\n",
      "<</SYS>>\n",
      "We've managed to reduce our energy consumption in our factory by about 15 per cent in the last two years . [/INST]\n",
      "\n",
      " *******************    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████████                                          | 5/10 [00:18<00:18,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wow, that's great to hear\n",
      "[INST] <<SYS>>\n",
      "Assume you are user and continue the conversation.\n",
      "<</SYS>>\n",
      "We've managed to reduce our energy consumption in our factory by about 15 per cent in the last two years . [/INST]\n",
      " That's excellent . How have you managed that ? </s>\n",
      "<s>[INST] Mainly because we've invested in a heat recovery system . [/INST]\n",
      " *******************    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████████████████████████████▍                                 | 6/10 [00:22<00:15,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ah, I see. Heat recovery systems\n",
      "[INST] <<SYS>>\n",
      "Assume you are user and continue the conversation.\n",
      "<</SYS>>\n",
      "Believe it or not , tea is the most popular beverage in the world after water . [/INST]\n",
      "\n",
      " *******************    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████▊                         | 7/10 [00:26<00:11,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wow, that's amazing!\n",
      "[INST] <<SYS>>\n",
      "Assume you are user and continue the conversation.\n",
      "<</SYS>>\n",
      "Believe it or not , tea is the most popular beverage in the world after water . [/INST]\n",
      " Well , people from Asia to Europe all enjoy tea . </s>\n",
      "<s>[INST] Right . And China is the homeland of tea . [/INST]\n",
      " *******************    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████████████████████████▏                | 8/10 [00:29<00:07,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ah, yes! China is indeed the birth\n",
      "[INST] <<SYS>>\n",
      "Assume you are user and continue the conversation.\n",
      "<</SYS>>\n",
      "What are your personal weaknesses ? [/INST]\n",
      "\n",
      " *******************    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████████████████████████████████████████████▌        | 9/10 [00:33<00:03,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Oh, boy, I'm glad you\n",
      "[INST] <<SYS>>\n",
      "Assume you are user and continue the conversation.\n",
      "<</SYS>>\n",
      "What are your personal weaknesses ? [/INST]\n",
      " I ’ m afraid I ’ m a poor talker . I ’ m not comfortable talking with the people whom I have just met for the first time . That is not very good for business , so I have been studying public speaking . </s>\n",
      "<s>[INST] Are you more of a leader or a follower ? [/INST]\n",
      " *******************    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [00:37<00:00,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hmm, that's a tough one\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>reference</th>\n",
       "      <th>act</th>\n",
       "      <th>act_label</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>prompt</th>\n",
       "      <th>gen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Hey man , you wanna buy some weed ? ]</td>\n",
       "      <td>Some what ?</td>\n",
       "      <td>2</td>\n",
       "      <td>Question</td>\n",
       "      <td>[1, 894, 2, 1, 18637, 767, 1919, 366, 281, 971...</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nAssume you are user and contin...</td>\n",
       "      <td>I cannot assist you with purchasing illegal su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Hey man , you wanna buy some weed ? ,  Some w...</td>\n",
       "      <td>Oh , umm , no thanks .</td>\n",
       "      <td>4</td>\n",
       "      <td>Commissive</td>\n",
       "      <td>[1, 1876, 790, 573, 2, 1, 18637, 767, 1919, 36...</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nAssume you are user and contin...</td>\n",
       "      <td>I see. Well, I don't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[The taxi drivers are on strike again . ]</td>\n",
       "      <td>What for ?</td>\n",
       "      <td>2</td>\n",
       "      <td>Question</td>\n",
       "      <td>[1, 894, 2, 1, 450, 8818, 29875, 18563, 526, 3...</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nAssume you are user and contin...</td>\n",
       "      <td>Oh no, that's really frustrating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[The taxi drivers are on strike again . ,  Wha...</td>\n",
       "      <td>It is really a hot potato .</td>\n",
       "      <td>1</td>\n",
       "      <td>Inform</td>\n",
       "      <td>[1, 15162, 2, 1, 450, 8818, 29875, 18563, 526,...</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nAssume you are user and contin...</td>\n",
       "      <td>Oh, I see. That's quite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[We've managed to reduce our energy consumptio...</td>\n",
       "      <td>That's excellent . How have you managed that ?</td>\n",
       "      <td>2</td>\n",
       "      <td>Question</td>\n",
       "      <td>[1, 894, 2, 1, 1334, 29915, 345, 8745, 304, 10...</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nAssume you are user and contin...</td>\n",
       "      <td>\\nWow, that's great to hear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[We've managed to reduce our energy consumptio...</td>\n",
       "      <td>What does that mean exactly ?</td>\n",
       "      <td>2</td>\n",
       "      <td>Question</td>\n",
       "      <td>[1, 894, 2, 1, 1334, 29915, 345, 8745, 304, 10...</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nAssume you are user and contin...</td>\n",
       "      <td>Ah, I see. Heat recovery systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Believe it or not , tea is the most popular b...</td>\n",
       "      <td>Well , people from Asia to Europe all enjoy t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Inform</td>\n",
       "      <td>[1, 15162, 2, 1, 3741, 2418, 372, 470, 451, 19...</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nAssume you are user and contin...</td>\n",
       "      <td>\\nWow, that's amazing!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Believe it or not , tea is the most popular b...</td>\n",
       "      <td>Yes , Chinese people love drinking tea so muc...</td>\n",
       "      <td>1</td>\n",
       "      <td>Inform</td>\n",
       "      <td>[1, 15162, 2, 1, 3741, 2418, 372, 470, 451, 19...</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nAssume you are user and contin...</td>\n",
       "      <td>Ah, yes! China is indeed the birth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[What are your personal weaknesses ? ]</td>\n",
       "      <td>I ’ m afraid I ’ m a poor talker . I ’ m not ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Inform</td>\n",
       "      <td>[1, 15162, 2, 1, 1724, 526, 596, 7333, 8062, 2...</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nAssume you are user and contin...</td>\n",
       "      <td>\\nOh, boy, I'm glad you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[What are your personal weaknesses ? ,  I ’ m ...</td>\n",
       "      <td>I don ’ t try to lead people . I ’ d rather c...</td>\n",
       "      <td>1</td>\n",
       "      <td>Inform</td>\n",
       "      <td>[1, 15162, 2, 1, 1724, 526, 596, 7333, 8062, 2...</td>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nAssume you are user and contin...</td>\n",
       "      <td>Hmm, that's a tough one</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0             [Hey man , you wanna buy some weed ? ]   \n",
       "1  [Hey man , you wanna buy some weed ? ,  Some w...   \n",
       "2          [The taxi drivers are on strike again . ]   \n",
       "3  [The taxi drivers are on strike again . ,  Wha...   \n",
       "4  [We've managed to reduce our energy consumptio...   \n",
       "5  [We've managed to reduce our energy consumptio...   \n",
       "6  [Believe it or not , tea is the most popular b...   \n",
       "7  [Believe it or not , tea is the most popular b...   \n",
       "8             [What are your personal weaknesses ? ]   \n",
       "9  [What are your personal weaknesses ? ,  I ’ m ...   \n",
       "\n",
       "                                           reference  act   act_label  \\\n",
       "0                                       Some what ?     2    Question   \n",
       "1                            Oh , umm , no thanks .     4  Commissive   \n",
       "2                                        What for ?     2    Question   \n",
       "3                       It is really a hot potato .     1      Inform   \n",
       "4    That's excellent . How have you managed that ?     2    Question   \n",
       "5                     What does that mean exactly ?     2    Question   \n",
       "6   Well , people from Asia to Europe all enjoy t...    1      Inform   \n",
       "7   Yes , Chinese people love drinking tea so muc...    1      Inform   \n",
       "8   I ’ m afraid I ’ m a poor talker . I ’ m not ...    1      Inform   \n",
       "9   I don ’ t try to lead people . I ’ d rather c...    1      Inform   \n",
       "\n",
       "                                        input_tokens  \\\n",
       "0  [1, 894, 2, 1, 18637, 767, 1919, 366, 281, 971...   \n",
       "1  [1, 1876, 790, 573, 2, 1, 18637, 767, 1919, 36...   \n",
       "2  [1, 894, 2, 1, 450, 8818, 29875, 18563, 526, 3...   \n",
       "3  [1, 15162, 2, 1, 450, 8818, 29875, 18563, 526,...   \n",
       "4  [1, 894, 2, 1, 1334, 29915, 345, 8745, 304, 10...   \n",
       "5  [1, 894, 2, 1, 1334, 29915, 345, 8745, 304, 10...   \n",
       "6  [1, 15162, 2, 1, 3741, 2418, 372, 470, 451, 19...   \n",
       "7  [1, 15162, 2, 1, 3741, 2418, 372, 470, 451, 19...   \n",
       "8  [1, 15162, 2, 1, 1724, 526, 596, 7333, 8062, 2...   \n",
       "9  [1, 15162, 2, 1, 1724, 526, 596, 7333, 8062, 2...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  [INST] <<SYS>>\\nAssume you are user and contin...   \n",
       "1  [INST] <<SYS>>\\nAssume you are user and contin...   \n",
       "2  [INST] <<SYS>>\\nAssume you are user and contin...   \n",
       "3  [INST] <<SYS>>\\nAssume you are user and contin...   \n",
       "4  [INST] <<SYS>>\\nAssume you are user and contin...   \n",
       "5  [INST] <<SYS>>\\nAssume you are user and contin...   \n",
       "6  [INST] <<SYS>>\\nAssume you are user and contin...   \n",
       "7  [INST] <<SYS>>\\nAssume you are user and contin...   \n",
       "8  [INST] <<SYS>>\\nAssume you are user and contin...   \n",
       "9  [INST] <<SYS>>\\nAssume you are user and contin...   \n",
       "\n",
       "                                                 gen  \n",
       "0  I cannot assist you with purchasing illegal su...  \n",
       "1                               I see. Well, I don't  \n",
       "2                   Oh no, that's really frustrating  \n",
       "3                            Oh, I see. That's quite  \n",
       "4                        \\nWow, that's great to hear  \n",
       "5                   Ah, I see. Heat recovery systems  \n",
       "6                             \\nWow, that's amazing!  \n",
       "7                 Ah, yes! China is indeed the birth  \n",
       "8                            \\nOh, boy, I'm glad you  \n",
       "9                            Hmm, that's a tough one  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_sentence(prompt,j):\n",
    "\n",
    "    print(prompt)    \n",
    "    print(\" *******************    \")\n",
    "    \n",
    "    input_id = tokenizer.encode(prompt,return_tensors ='pt')\n",
    "    output_so_far  = input_id\n",
    "    last = output_so_far[:, -1:] # 마지막 단어\n",
    "    past = model(output_so_far[:, :-1],return_dict =True)[\"past_key_values\"] #이전단어들의 key_value\n",
    "    \n",
    "    \n",
    "    for i in range(10):\n",
    "        lm_output= model(last, past_key_values=past,use_cache = True,\n",
    "                         return_dict=True,output_hidden_states=True)  \n",
    "        logit, past = (\n",
    "            lm_output[\"logits\"], \n",
    "            # torch.Size([1, 1, 32000]\n",
    "            \n",
    "            lm_output[\"past_key_values\"]) \n",
    "            # 32, 2, torch.Size([1, 32, Sequence_len, 128]) )\n",
    "        probs = nn.functional.softmax(logit[:,-1,:], dim=-1)\n",
    "        last = torch.topk(probs, k=1, dim=-1)[1]\n",
    "        \n",
    "        output_so_far = torch.cat((output_so_far,last),dim=1)\n",
    "        \n",
    "        del lm_output\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        if last[0] ==torch.tensor(tokenizer.eos_token_id):\n",
    "            break\n",
    "    print(tokenizer.decode(output_so_far[0][len(input_id[0]):])) \n",
    "    return tokenizer.decode(output_so_far[0][len(input_id[0]):])\n",
    "\n",
    "gen = []\n",
    "for j in tqdm(range(len(data))):\n",
    "    gen.append(generate_sentence(data['prompt'][j],j))\n",
    "data['gen'] = gen\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOBGc3WgJTvwgp7jiBxY7Pp",
   "machine_shape": "hm",
   "mount_file_id": "1PV25_eTqPr-jNz23RBXDrs1KICBozvHF",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0f42b149c38040799aa77a06e1be37a3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b0b2a196cf04039aae27141cbb342b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f42b149c38040799aa77a06e1be37a3",
      "placeholder": "​",
      "style": "IPY_MODEL_88e2fe42ee704457951b0a433aa7e6c3",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "7c676819d0bc46deab79af55576cb680": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6b0b2a196cf04039aae27141cbb342b8",
       "IPY_MODEL_8841468b83e14fc793f090f195562ecc",
       "IPY_MODEL_e85aa133d0024c7d918d19d49ebfda1f"
      ],
      "layout": "IPY_MODEL_f2aab9cbec914614958c8429ff658730"
     }
    },
    "7d8dff2afdfe41968ee79c9acdbdcb42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8841468b83e14fc793f090f195562ecc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8bdade393b64daeaa3211d74b7962ff",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f23de0e1ffc8491fae098ba5f55c2e00",
      "value": 2
     }
    },
    "88e2fe42ee704457951b0a433aa7e6c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aca0418d6fe24fa3a9a9c939ad83c012": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8bdade393b64daeaa3211d74b7962ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e85aa133d0024c7d918d19d49ebfda1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aca0418d6fe24fa3a9a9c939ad83c012",
      "placeholder": "​",
      "style": "IPY_MODEL_7d8dff2afdfe41968ee79c9acdbdcb42",
      "value": " 2/2 [00:05&lt;00:00,  2.43s/it]"
     }
    },
    "f23de0e1ffc8491fae098ba5f55c2e00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f2aab9cbec914614958c8429ff658730": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
